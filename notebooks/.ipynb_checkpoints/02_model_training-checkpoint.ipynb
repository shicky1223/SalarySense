{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6093fd3",
   "metadata": {},
   "source": [
    "Model Training & Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c08b39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d575c40",
   "metadata": {},
   "source": [
    "Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "762e8fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (15000, 66)\n",
      "Labels shape:   (15000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   years_experience  benefits_score  job_description_length  exp_level_ord  \\\n",
       " 0                 9             5.9                    1076              2   \n",
       " 1                 1             5.2                    1268              0   \n",
       " 2                 2             9.4                    1974              1   \n",
       " 3                 7             8.6                    1345              2   \n",
       " 4                 0             6.6                    1989              0   \n",
       " \n",
       "    company_size_ord  remote_ratio  post_month  skill_python  skill_sql  \\\n",
       " 0                 1            50          10             0          0   \n",
       " 1                 1           100          11             1          0   \n",
       " 2                 2             0           3             0          0   \n",
       " 3                 1            50          12             1          1   \n",
       " 4                 0           100           4             1          0   \n",
       " \n",
       "    skill_tensorflow  ...  company_location_Israel  company_location_Japan  \\\n",
       " 0                 0  ...                    False                   False   \n",
       " 1                 0  ...                    False                   False   \n",
       " 2                 0  ...                    False                   False   \n",
       " 3                 0  ...                    False                   False   \n",
       " 4                 0  ...                    False                   False   \n",
       " \n",
       "    company_location_Netherlands  company_location_Norway  \\\n",
       " 0                         False                    False   \n",
       " 1                         False                    False   \n",
       " 2                         False                    False   \n",
       " 3                         False                    False   \n",
       " 4                         False                    False   \n",
       " \n",
       "    company_location_Singapore  company_location_South Korea  \\\n",
       " 0                       False                         False   \n",
       " 1                       False                         False   \n",
       " 2                       False                         False   \n",
       " 3                       False                         False   \n",
       " 4                       False                         False   \n",
       " \n",
       "    company_location_Sweden  company_location_Switzerland  \\\n",
       " 0                    False                         False   \n",
       " 1                    False                         False   \n",
       " 2                    False                          True   \n",
       " 3                    False                         False   \n",
       " 4                    False                         False   \n",
       " \n",
       "    company_location_United Kingdom  company_location_United States  \n",
       " 0                            False                           False  \n",
       " 1                            False                           False  \n",
       " 2                            False                           False  \n",
       " 3                            False                           False  \n",
       " 4                            False                           False  \n",
       " \n",
       " [5 rows x 66 columns],\n",
       "    log_salary\n",
       " 0   11.411745\n",
       " 1   11.033211\n",
       " 2   11.935752\n",
       " 3   11.292478\n",
       " 4   10.908247)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES_PATH = \"../data/processed/features.csv\"\n",
    "LABELS_PATH   = \"../data/processed/labels.csv\"\n",
    "X = pd.read_csv(FEATURES_PATH)\n",
    "y = pd.read_csv(LABELS_PATH)\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:  \", y.shape)\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8342b9",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87aae46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10500, 66), (10500,)\n",
      "Val   shape: (2250, 66), (2250,)\n",
      "Test  shape: (2250, 66), (2250,)\n"
     ]
    }
   ],
   "source": [
    "if isinstance(y, pd.DataFrame):\n",
    "    y = y.iloc[:, 0]\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")\n",
    "relative_val_size = 0.15 / 0.85  # so that val = 0.15 of total\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=relative_val_size, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Val   shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test  shape: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730bcc4f",
   "metadata": {},
   "source": [
    "We hold out 15% of the data for a final test set.\n",
    "From the remaining 85%, we take 15/85 ≈ 17.6% (which is ~15% of the original) as a validation set.\n",
    "This results in roughly 70% train / 15% val / 15% test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e14436",
   "metadata": {},
   "source": [
    "Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aaa87fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['years_experience', 'benefits_score', 'job_description_length', 'remote_ratio', 'post_month', 'exp_level_ord', 'company_size_ord']\n",
      "Categorical features: ['industry_Healthcare', 'company_location_Singapore', 'company_location_Switzerland', 'company_location_United Kingdom', 'skill_data visualization'] ... (total 59)\n"
     ]
    }
   ],
   "source": [
    "numeric_features = [\n",
    "    \"years_experience\",\n",
    "    \"benefits_score\",\n",
    "    \"job_description_length\",\n",
    "    \"remote_ratio\",\n",
    "    \"post_month\"  \n",
    "]\n",
    "numeric_features += [\"exp_level_ord\", \"company_size_ord\"]\n",
    "all_cols = set(X.columns.tolist())\n",
    "numeric_set = set(numeric_features)\n",
    "categorical_features = list(all_cols - numeric_set)\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features[:5], \"...\", f\"(total {len(categorical_features)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72061749",
   "metadata": {},
   "source": [
    "Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d52847b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  \n",
    "    \n",
    ")\n",
    "linreg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34ff14",
   "metadata": {},
   "source": [
    "Train and Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e79495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (baseline) — Validation RMSE: 0.14, R2: 0.918\n"
     ]
    }
   ],
   "source": [
    "linreg_pipeline.fit(X_train, y_train)\n",
    "y_val_pred = linreg_pipeline.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "print(f\"Linear Regression (baseline) — Validation RMSE: {rmse_val:.2f}, R2: {r2_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b9fe4",
   "metadata": {},
   "source": [
    "The R^2 value here is 0.918 and the RMSE is 0.14. This is a very promising result as it means that our model does an excellent job at prediciting salary most of the salary fluctuations align with linear effects of your features. Any more complex model would have limited room for improvement beyond this baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c2611",
   "metadata": {},
   "source": [
    "Advanced Model: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "587580e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", xgb_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d176310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (default) — Validation RMSE: 0.15, R2: 0.904\n"
     ]
    }
   ],
   "source": [
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_val_pred_xgb = xgb_pipeline.predict(X_val)\n",
    "rmse_val_xgb = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
    "r2_val_xgb   = r2_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost (default) — Validation RMSE: {rmse_val_xgb:.2f}, R2: {r2_val_xgb:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922109d7",
   "metadata": {},
   "source": [
    "Model Comparison (Validation Results)\n",
    "\n",
    "Linear Regression (baseline)\n",
    "RMSE = 0.14\n",
    "R² = 0.918\n",
    "This model explains 91.8 % of the variance in salary and produces an average error of 0.14 (in our target’s transformed scale), indicating a very strong linear signal in the data.\n",
    "XGBoost (default hyperparameters)\n",
    "RMSE = 0.15\n",
    "R² = 0.904\n",
    "With out‐of‐the‐box settings, XGBoost underperforms: it explains only 90.4 % of the variance and has a slightly larger average error (0.15).\n",
    "Key Takeaways\n",
    "\n",
    "The high R² and low RMSE for linear regression show that most of the salary variation is captured by simple additive (linear) effects of our features.\n",
    "Default XGBoost fails to improve—and even slightly worsens—both RMSE and R², suggesting few nonlinearities or interactions remain for it to learn.\n",
    "Unless we carefully tune XGBoost’s parameters, a linear model is both more interpretable and more accurate in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ded3c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best parameters: {'regressor__learning_rate': 0.05, 'regressor__max_depth': 4, 'regressor__n_estimators': 300, 'regressor__subsample': 0.8}\n",
      "Best CV RMSE (train folds): 0.14\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"regressor__n_estimators\": [100, 300],\n",
    "    \"regressor__max_depth\": [4, 6],\n",
    "    \"regressor__learning_rate\": [0.05, 0.1],\n",
    "    \"regressor__subsample\": [0.8, 1.0]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",  # GridSearchCV maximizes, so we use negative MSE\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_rmse_cv = np.sqrt(-grid_search.best_score_)\n",
    "print(f\"Best CV RMSE (train folds): {best_rmse_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "613ffb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGB — Validation RMSE: 0.14, R2: 0.916\n",
      "Tuned XGB — Test RMSE: 0.14, R2: 0.915\n"
     ]
    }
   ],
   "source": [
    "best_xgb_pipeline = grid_search.best_estimator_\n",
    "y_val_pred_best = best_xgb_pipeline.predict(X_val)\n",
    "rmse_val_best = np.sqrt(mean_squared_error(y_val, y_val_pred_best))\n",
    "r2_val_best = r2_score(y_val, y_val_pred_best)\n",
    "print(f\"Tuned XGB — Validation RMSE: {rmse_val_best:.2f}, R2: {r2_val_best:.3f}\")\n",
    "y_test_pred = best_xgb_pipeline.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test   = r2_score(y_test, y_test_pred)\n",
    "print(f\"Tuned XGB — Test RMSE: {rmse_test:.2f}, R2: {r2_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857db83",
   "metadata": {},
   "source": [
    "After hyperparameter tuning, the XGBoost model achieves a validation RMSE of 0.14 with an R² of 0.916, and on the independent test set it maintains an RMSE of 0.14 and an R² of 0.915. In other words, the tuned model explains roughly 91.6 % of the variance in salary on the validation data and 91.5 % on unseen test data, with average prediction errors that remain very low (around 0.14 in our transformed salary scale). The near‐identical performance between validation and test indicates that the model is not overfitting; it generalizes well to new data. Moreover, since these figures are effectively on par with the baseline linear regression (which had an R² of 0.918), it implies that any remaining nonlinear patterns or interactions in the data were minimal—tuning XGBoost simply matched the strong linear signal rather than dramatically exceeding it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbeeb14",
   "metadata": {},
   "source": [
    "Persist the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eb98ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model pipeline to: ../models/salary_model.pkl\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"../models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"salary_model.pkl\")\n",
    "joblib.dump(best_xgb_pipeline, MODEL_PATH)\n",
    "\n",
    "print(f\"Saved trained model pipeline to: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0473be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessor to: ../models/preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "preprocessor_fitted = best_xgb_pipeline.named_steps[\"preprocessor\"]\n",
    "PREPROCESSOR_PATH = os.path.join(MODEL_DIR, \"preprocessor.pkl\")\n",
    "joblib.dump(preprocessor_fitted, PREPROCESSOR_PATH)\n",
    "print(f\"Saved preprocessor to: {PREPROCESSOR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836b588",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
